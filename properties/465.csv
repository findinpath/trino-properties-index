version,jar,plugin,config,description,is_deprecated
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large.max-size-per-filter,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-compute-task-target-size-min,"Initial/min target input size for non-writer tasks of arbitrary distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.exhausted-node-wait-period,"Maximum time to wait for resource availability on preferred nodes before scheduling a remotely accessible split on other nodes. Relevant for TASK retry policy only.",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.service-name,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.read-only,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.password.user-mapping.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.page-buffer-client.max-callback-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-hash-distribution-write-task-target-size,"Target input size of writer tasks of hash distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.concurrent-request-multiplier,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,event.max-output-stage-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.experimental-max-prefetched-information-schema-prefixes,"Experimental: maximum number of internal ""prefixes"" to be prefetched when optimizing information_schema queries",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.min-pending-splits-per-task,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.enable-intermediate-aggregations,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.share-index-loading,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.initial-splits-per-node,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.jwt-type,"Custom JWT type for server to use",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.determine-partition-count-for-write-enabled,"Determine the number of partitions based on amount of data read and processed by the query for write queries",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.retrieval-mode,"Determines how the client will retrieve the segment",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.key-file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,pages-index.eager-compaction-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-concurrent-queries,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,experimental.protocol.spooling.enabled,"Enable experimental spooling client protocol server-side support",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task-retry-attempts-per-task,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-runtime-adaptive-partitioning-max-task-size,"Max average task input size when deciding runtime adaptive partitioning",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query-retry-attempts,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.shared-secret,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.password.user-mapping.pattern,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,experimental.columnar-filter-evaluation.enabled,"Enables columnar evaluation of filters",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.schedule-split-batch-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.client.timeout,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.principal-field,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,max-tasks-waiting-for-node-per-query,"Maximum possible number of tasks waiting for node allocation per query before scheduling of new tasks for query is paused",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spill-encryption-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-index-memory,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.min-candidates,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.info-url-template,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.inlining.max-rows,"Maximum number of rows that are allowed to be inlined per worker",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.include-coordinator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.https.required,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,distributed-sort,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,enable-forced-exchange-below-group-id,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,scale-writers,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.reported-rule-stats-limit,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.required-audience,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,plugin.dir,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.user-mapping.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.keytab,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.distinct-aggregations-strategy,"Strategy to use for distinct aggregations",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large.max-size-per-operator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.inlining.max-size,"Maximum size of rows that are allowed to be inlined per worker",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,driver.page-partitioning-buffer-pool-size,"Maximum number of free buffers in the per task partitioned page buffer pool. Setting this to zero effectively disables the pool",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.disabled-catalogs,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.disabled-catalogs,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,access-control.config-files,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query-results.compression-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http.authentication.krb5.config,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large.max-distinct-values-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.push-partial-aggregation-through-join,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.max-adjusted-pending-splits-per-task,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-min-partition-count,"Minimum number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,driver.max-page-partitioning-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.user,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,failure-detector.threshold,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-adaptive-join-reordering-size-difference-ratio,"The ratio of difference in estimated size of right and left side of join to consider reordering",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.end-session-url,"URL of the end session endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sink.max-broadcast-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-planning-time,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.prefer-partial-aggregation,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.manager-executor-pool-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-write-task-target-size-max,"Max target input size for writer tasks of arbitrary distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.data-integrity-verification,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.max-request-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-runtime-adaptive-partitioning-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.skip-redundant-sort,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-adaptive-query-planning-enabled,"Enable adaptive query planning for the fault tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,use-preferred-write-partitioning,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.min-input-rows-per-task,"Minimum input rows required per task. This will help optimizer determine hash partition count for joins and aggregations",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-write-task-target-size-growth-factor,"Growth factor for adaptive sizing of writer tasks of arbitrary distribution for fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.policy,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.execution-policy,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.segments,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sql.default-schema,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small.max-size-per-filter,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,enable-dynamic-filtering,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,deprecated.http-server.authentication.oauth2.groups-field,"Groups field in the claim. This configuration is scheduled for removal.",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.allow-unsafe-pushdown,"Allow pushing down expressions that mail fail for some inputs",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.optimize-top-n-ranking,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.https.keystore.path,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spill-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large.range-row-limit-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-min-partition-count-for-write,"Minimum number of partitions for distributed joins and aggregations in write queries executed with fault tolerant execution enabled",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.min-schedule-split-batch-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.https.truststore.key,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.push-filter-into-values-max-row-count,"Maximum number of rows in values for which filter is pushed down into values",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-memory-per-node,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.enable-adaptive-request-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.optimize-hash-generation,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-run-time,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,filter-and-project-min-output-page-row-count,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,max-tasks-waiting-for-execution-per-query,"Maximum number of tasks waiting to be scheduled per query. Split enumeration is paused by the scheduler when this threshold is crossed",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.info-update-interval,"Interval between updating task data",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-hash-distribution-write-task-target-max-count,"Soft upper bound on number of writer tasks in a stage of hash distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,retry-policy,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-small-stage-estimation-enabled,"Enable small stage estimation heuristic, used for more aggresive speculative stage scheduling",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.https.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.config-dir,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.config-dir,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,max-memory-per-partition-writer,"Estimated maximum memory required per partition writer in a single thread",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-max-partition-count,"Maximum number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-length,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-exchange-encryption-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.request-size-headroom,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-partial-top-n-memory,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.max-callback-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http.include-exception-in-response,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-descriptor-storage-high-water-mark,"Compress the storage when task descriptors in memory are above given data size",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-write-task-target-size-growth-period,"The number of tasks created for any given writer stage of arbitrary distribution before task size is increased",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-writer-task-count,"Maximum number of tasks that will participate in writing data",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.force-single-node-output,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-compute-task-target-size-growth-period,"The number of tasks created for any given non-writer stage of arbitrary distribution before task size is increased",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.http-timeout-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.encoding.json+lz4.enabled,"Enable LZ4 compressed json spooled encoding",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.prune.update-interval,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.acknowledge-pages,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.cpu-timer-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spiller-max-used-space-threshold,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-queued-queries,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,enable-large-dynamic-filters,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.use-cost-based-partitioning,"When enabled the cost based optimizer is used to determine if repartitioning the output of an already partitioned stage is necessary",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,failure-detector.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,warning-collector.max-warnings,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-compute-task-target-size-growth-factor,"Growth factor for adaptive sizing of non-writer tasks of arbitrary distribution for fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.max-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,join-distribution-type,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.max-error-duration,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.per-operator-cpu-timer-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.min-hash-partition-count,"Minimum number of partitions for distributed joins and aggregations",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.user-mapping.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-memory-requirement-increase-on-worker-crash-enabled,"Increase memory requirement for tasks failed due to a suspected worker crash",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-partial-aggregation-memory,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-small-stage-estimation-threshold,"Threshold until which stage is considered small",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.push-aggregation-through-outer-join,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,statistics-precalculation-for-pushdown.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spiller-spill-path,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.push-table-write-through-union,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,compiler.specialized-aggregation-loops,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-memory,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.driver-timeout-threads,"Number of threads used for timing out blocked drivers if the timeout is set",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,adaptive-partial-aggregation.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,memory-cost-weight,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,aggregation-operator-unspill-memory-limit,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-adaptive-join-reordering-min-size-threshold,"The minimum size of the right side of join to consider reordering",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.dispatcher-query-pool-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.min-hash-partition-count-for-write,"Minimum number of partitions for distributed joins and aggregations in write queries",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.https.keystore.key,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied. Relevant for TASK retry policy only.",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spill-compression-codec,"Compression codec used for data in spills",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.certificate.user-mapping.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.max-response-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.preview.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.min-writer-count,"Minimum number of local parallel table writers per task when preferred partitioning and task writer scaling are not used",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,cpu-cost-weight,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,redistribute-writes,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.jwt.required-issuer,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-eager-speculative-tasks-node-memory-overcommit,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,deprecated.regex-library,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.ignore-downstream-preferences,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,internal-communication.https.truststore.path,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-adaptive-join-reordering-enabled,"Reorder partitioned join based on run time stats in fault tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,coordinator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-scan-physical-bytes,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,re2j.dfa-states-limit,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,event-listener.config-files,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,failure-detector.heartbeat-interval,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-cpu-time,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-standard-split-size,"Standard split size for a single fault tolerant task (split weight aware)",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.merge-project-with-values,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,compiler.expression-cache-size,"Reuse compiled expressions across multiple queries",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.large.max-size-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,discovery-server.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.complex-expression-pushdown.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,filter-and-project-min-output-page-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.shared-secret,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.min-expire-age,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.shared-secret-key,"256 bit, base64-encoded secret key used to secure segment identifiers",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.http-response-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.max-error-duration,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.inlining.enabled,"Allow spooled protocol to inline data",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.deduplication-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-descriptor-storage-low-water-mark,"Do not compress the storage when tasks descriptors in memory are below given data size",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-small-stage-source-size-multiplier,"Multiplier used for heuristic estimation is stage is small; the bigger the more conservative estimation is",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-execution-time,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,writer-scaling-min-data-processed,"Minimum amount of uncompressed output data processed by writers before writer scaling can happen",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,shutdown.grace-period,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sql.default-function-schema,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small.max-distinct-values-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-total-memory,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.min-input-size-per-task,"Minimum input data size required per task. This will help optimizer determine hash partition count for joins and aggregations",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,max-spill-per-node,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.refresh-period,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.low-memory-killer.policy,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.remote-task.guaranteed-splits-per-task,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-hash-distribution-compute-task-target-size,"Target input size for non-writer tasks of hash distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-hash-distribution-compute-task-to-node-min-ratio,"Minimal ratio of tasks count vs cluster nodes count for hash distributed compute stage in fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small.range-row-limit-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,network-cost-weight,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,jmx.base-name,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,analyzer.max-grouping-sets,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.split-concurrency-adjustment-interval,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.encoding.json+zstd.enabled,"Enable Zstd compressed json spooled encoding",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.client-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-split-manager-callback-threads,"The maximum number of threads allowed to run splits generation callbacks concurrently",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,colocated-joins-enabled,"Use a colocated join when possible",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.type,"Ordered list of authentication types",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.optimized-local-scheduling,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.name-type,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-stage-count,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-row-filtering.selectivity-threshold,"Avoid using dynamic row filters when fraction of rows selected is above threshold",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small.max-size-per-driver,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query-max-spill-per-node,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.client.timeout,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-write-task-target-size-min,"Initial/min target input size for writer tasks of arbitrary distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.management,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-worker-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-min-source-stage-progress,"Minimal progress of source stage to consider scheduling of parent stage",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,enable-stats-calculator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sql.default-function-catalog,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-stage-estimation-for-eager-parent-enabled,"Enable aggressive stage output size estimation heuristic for children of stages to be executed eagerly",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.initial-segment-size,"Initial size of the spooled segments in bytes",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-small-stage-require-no-more-partitions,"Is it required for all stage partitions (tasks) to be enumerated for stage to be used in heuristic to determine if parent stage is small",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.coordinator-storage-redirect-ttl,"Determines how long the pre-signed URI generated by the coordinator allows for retrieval of data",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-hash-partition-count,"Maximum number of partitions for distributed joins and aggregations",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.min-drivers,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,iterative-optimizer-timeout,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.maximum-segment-size,"Maximum size of the spooled segments in bytes",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.statistics-cpu-timer-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,re2j.dfa-retries,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.low-memory-killer.policy,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.krb5.principal-hostname,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.default-filter-factor-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-arbitrary-distribution-compute-task-target-size-max,"Max target input size for non-writer task of arbitrary distribution of fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.insecure.user-mapping.file,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-hash-distribution-write-task-to-node-min-ratio,"Minimal ratio of tasks count vs cluster nodes count for hash distributed writer stage in fault-tolerant execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-runtime-adaptive-partitioning-partition-count,"The partition count to use for runtime adaptive partitioning when enabled",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.termination-timeout,"Maximum duration to wait for a task to complete termination before failing the task on the coordinator",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-history,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sql.default-catalog,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,sink.max-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,spiller-threads,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.executor-pool-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.optimize-metadata-queries,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,web-ui.session-timeout,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,dynamic-filtering.small.max-size-per-operator,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.type,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.info.max-age,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.prune.enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-writer-count,"Maximum number of local parallel table writers per task when either task writer scaling or preferred partitioning is used",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,exchange.compression-codec,"Compression codec used for data in exchanges",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.max-splits-per-node,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,optimizer.dictionary-aggregation,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,query.max-state-machine-callback-threads,"The maximum number of threads allowed to run query and stage state machine listener callbacks concurrently for each query",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.status-refresh-max-wait,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,catalog.store,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,experimental.thread-per-driver-scheduler-enabled,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,task.max-local-exchange-buffer-size,"",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,enable-dynamic-row-filtering,"Enable fine-grained filtering of rows in the scan operator using dynamic filters",false
465,trino-server-465/lib/io.trino_trino-main-465.jar,,protocol.spooling.encoding.json.enabled,"Enable uncompressed json spooled encoding",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,case-insensitive-name-matching.cache-ttl,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,case-insensitive-name-matching.config-file,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,case-insensitive-name-matching.config-file.refresh-period,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.timeout.connect,"Timeout for establishing a connection",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,security.config-file,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,security.refresh-period,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.ssl.keystore.password,"Password for the key store",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.url,"URL of the LDAP server",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.ssl.truststore.password,"Password for the trust store",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,case-insensitive-name-matching,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.timeout.read,"Timeout for reading data from LDAP",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,jmx.base-name,"",false
465,trino-server-465/lib/io.trino_trino-plugin-toolkit-465.jar,,security.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.job.label-name,"Adds label with the given name to the BigQuery job",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-timeout,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.channel-pool.max-size,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.truststore-password,"Password to a Java truststore file",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.view-materialization-with-filter,"Use filter when materializing views",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.metadata.parallelism,"Limits metadata enumeration calls parallelism",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.query-results-cache.enabled,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-retry-delay-multiplier,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.metadata.cache-ttl,"Duration for which BigQuery client metadata is cached after listing",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.channel-pool.min-size,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.arrow-serialization.enabled,"Enables Arrow serialization while reading data",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.keystore-password,"Password to a Java keystore file",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.uri,"Proxy URI (host and port only)",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.username,"Username used to authenticate against proxy",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.case-insensitive-name-matching.cache-ttl,"Duration for which case insensitive schema and table names are cached. Set to 0ms to disable the cache.",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.view-expire-duration,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.projection-pushdown-enabled,"Dereference push down for ROW type",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-retries,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.truststore-path,"Path to a Java truststore file",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.password,"Password used to authenticate against proxy",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.channel-pool.min-rpc-per-channel,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-retry-delay,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.channel-pool.max-rpc-per-channel,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.job.label-format,"Adds `bigquery.job.label-name` label to the BigQuery job with provided value format",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.enabled,"Enables proxying of RPC and gRPC requests to BigQuery APIs",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.channel-pool.initial-size,"",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.rpc-proxy.keystore-path,"Path to a Java keystore file",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.legacy-metadata-listing,"Call BigQuery REST API per table when listing metadata",false
465,trino-server-465/plugin/bigquery/io.trino_trino-bigquery-465.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.protocol-version,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.client.so-linger,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.retry-policy,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.client.connect-timeout,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.splits-per-node,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.tls.keystore-password,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.contact-points,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.client.read-timeout,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.speculative-execution.delay,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.tls.enabled,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.tls.truststore-password,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.split-size,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.speculative-execution.limit,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.password,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.batch-size,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.username,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.tls.keystore-path,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.consistency-level,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.fetch-size,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.tls.truststore-path,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.native-protocol-port,"",false
465,trino-server-465/plugin/cassandra/io.trino_trino-cassandra-465.jar,cassandra,cassandra.security,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-password-credential-password,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,query.reuse-connection,"Enables reusing JDBC connection for metadata queries to data source within a single Trino query",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-password,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,query.comment-format,"Format in which logs about query execution context should be added as comments sent through jdbc driver.",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-file-path,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,jdbc.bulk-list-columns.enabled,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,write.parallelism,"Maximum number of parallel write tasks",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-user-credential-name,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.schemas.cache-ttl,"Determines how long schema names list information will be cached",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.statistics.cache-ttl,"Determines how long table statistics information will be cached",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,connection-user,"user name for JDBC client",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,connection-password,"Password for JDBC client",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-password-credential-name,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,connection-url,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-type,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,complex-expression-pushdown.enabled,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,user-credential-name,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,statistics.enabled,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.tables.cache-ttl,"Determines how long table names list information will be cached",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,keystore-user-credential-password,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,join-pushdown.with-expressions,"Enable join pushdown with complex expressions",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,credential-provider.type,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,join-pushdown.strategy,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,password-credential-name,"",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-base-jdbc-465.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
465,trino-server-465/plugin/clickhouse/io.trino_trino-clickhouse-465.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-filesystem-465.jar,delta-lake,fs.memory-cache.ttl,"Duration to keep files in the cache prior to eviction",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-filesystem-465.jar,delta-lake,fs.memory-cache.max-size,"Maximum total size of the cache",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-filesystem-465.jar,delta-lake,fs.cache.preferred-hosts-count,"The number of preferred nodes for caching a file. Defaults to 2.",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-filesystem-465.jar,delta-lake,fs.memory-cache.max-content-length,"Maximum size of file that can be cached",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.port,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.adl-client-id,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs-timeout,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.connect-ttl,"TCP connect TTL in the client side, which affects connection reusage",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.signer-class,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.host,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.domain-socket-path,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.max-error-retries,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.socks-proxy,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.sts.region,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.sts.endpoint,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.region,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.max-connections,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.connect.max-retries,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.adl-refresh-url,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.verify-checksum,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.fs.new-file-inherit-ownership,"Flag to determine if new files inherit the ownership information from the directory.",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.gcs.json-key,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.ssl.enabled,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.max-client-retries,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.protocol,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.aws-secret-key,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.max-retry-time,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.abfs-access-key,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.adl-proxy-host,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.connect-timeout,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.endpoint,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.streaming.enabled,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.wasb-access-key,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.abfs-storage-account,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.max-backoff-time,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.signer-type,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3-file-system-type,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.aws-access-key,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.username,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.cos.service-config,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.wasb-storage-account,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.config.resources,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.socket-timeout,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.dfs.connect.timeout,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.s3.proxy.password,"",false
465,trino-server-465/plugin/delta-lake/hdfs/io.trino_trino-hdfs-465.jar,delta-lake,hive.azure.adl-credential,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.register-table-procedure.enabled,"Allow users to call the register_table procedure",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metadata.cache-size,"Maximum number of Delta table metadata entries to cache",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.query-partition-filter-required,"Require filter on at least one partition column",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.idle-writer-min-file-size,"Minimum data written by a single partition writer before it can be consider as 'idle' and could be closed by the engine",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metastore.store-table-metadata-threads,"Number of threads used for storing table metadata in metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.max-split-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.fs.cache.disable-transaction-log-caching,"Disable filesystem caching of the _delta_log directory (effective only when fs.cache.enabled=true)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.projection-pushdown-enabled,"Read only required fields from a row type",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metastore.store-table-metadata,"Store table metadata in metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metastore.store-table-metadata-interval,"Interval to store table metadata in metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.checkpoint-filtering.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.deletion-vectors-enabled,"Enable deletion vectors by default for new tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.extended-statistics.collect-on-write,"Enables automatic column level extended statistics collection on write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-delta-lake-465.jar,delta-lake,delta.extended-statistics.enabled,"Enable collection (ANALYZE) and use of extended statistics.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.max-single-upload-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.oauth.tenant-id,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.max-http-requests,"Maximum number of concurrent HTTP requests to Azure on every node",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.oauth.client-id,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.max-write-concurrency,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.auth-type,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.endpoint,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.write-block-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.oauth.secret,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.access-key,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.read-block-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-azure-465.jar,delta-lake,azure.oauth.endpoint,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-cache-alluxio-465.jar,delta-lake,fs.cache.page-size,"Page size for cache",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-cache-alluxio-465.jar,delta-lake,fs.cache.max-disk-usage-percentages,"The maximum percentage (0-100) of total disk size the cache can use. Use a comma-separated list of percentage values if supplying several cache directories.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-cache-alluxio-465.jar,delta-lake,fs.cache.ttl,"Duration to keep files in the cache prior to eviction",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-cache-alluxio-465.jar,delta-lake,fs.cache.max-sizes,"The maximum cache size for a cache directory. Use a comma-separated list of sizes to specify allowed maximum values for each directory.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-cache-alluxio-465.jar,delta-lake,fs.cache.directories,"Base directory to cache data. Use a comma-separated list to cache data in multiple directories.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.client.max-retry-time,"Total time limit for an RPC to be retried",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.page-size,"The maximum number of blobs to return per page.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.batch-size,"Number of blobs to delete per batch. Recommended batch size is 100: https://cloud.google.com/storage/docs/batch",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.read-block-size,"Minimum size that will be read in one RPC. The default size is 2MiB, see com.google.cloud.BaseStorageReadChannel.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.write-block-size,"Minimum size that will be written in one RPC. The default size is 16MiB, see com.google.cloud.BaseStorageWriteChannel.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.use-access-token,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.project-id,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.client.backoff-scale-factor,"Scale factor for RPC retry delay",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.client.max-backoff-delay,"Maximum delay between RPC retries.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.client.min-backoff-delay,"Minimum delay between RPC retries",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.json-key,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-gcs-465.jar,delta-lake,gcs.client.max-retries,"Maximum number of RPC attempts",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.alluxio.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.native-azure.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.native-s3.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.cache.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.hadoop.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-manager-465.jar,delta-lake,fs.native-gcs.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.requester-pays,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy.password,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.sse.type,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.exclusive-create,"Whether S3-compatible storage supports exclusive create (true for Minio and AWS S3)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.region,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.path-style-access,"Use path-style access for all requests to S3",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.max-error-retries,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.socket-read-timeout,"Maximum time allowed for socket reads before timing out",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.connection-max-idle-time,"Maximum time allowed for connections to remain idle in the connection pool before being closed",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.use-web-identity-token-credentials-provider,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.role-session-name,"Role session name to use when connecting to S3",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.aws-access-key,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy.username,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.config-file,"Path to the JSON security mappings file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy.non-proxy-hosts,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.aws-secret-key,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.max-connections,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.sts.region,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.canned-acl,"Canned ACL (predefined grants) to manage access to objects",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.config-uri,"HTTP URI of the JSON security mappings",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.socket-connect-timeout,"Maximum time allowed for socket connect to complete before timing out",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.connection-ttl,"Maximum time allowed for connections to be reused before being replaced in the connection pool",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.sts.endpoint,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.retry-mode,"Specifies how the AWS SDK attempts retries, default is LEGACY",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy.secure,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.tcp-keep-alive,"Enable TCP keep alive on created connections",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.sse.customer-key,"Customer Key to use for S3 server-side encryption with Customer key (SSE-C)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.streaming.part-size,"Part size for S3 streaming upload",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.http-proxy.preemptive-basic-auth,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-filesystem-s3-465.jar,delta-lake,s3.endpoint,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,writer-sort-buffer-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.use-web-identity-token-credentials-provider,"If true, explicitly use the WebIdentityTokenCredentialsProvider instead of the default credential provider chain.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.recursive-directories,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.read-timeout,"Socket read timeout for metastore client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.auto-purge,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.http.client.read-timeout,"Socket read timeout for metastore client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache-ttl,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.allow-register-partition-procedure,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.small-file-threshold,"Size below which a parquet file will be read entirely",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.writer.page-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.max-merge-distance,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.force-local-scheduling,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-split-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.sts.region,"AWS STS signing region for Glue authentication",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.sts.region,"AWS STS signing region for Glue authentication",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.ignore-absent-partitions,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.file-status-cache-tables,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.storage-format,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.file-status-cache-expire-time,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache.cache-missing,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.catalog-name,"Hive metastore thrift catalog name",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.max-merge-distance,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache.cache-missing-partitions,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.sts.endpoint,"AWS STS endpoint for Glue authentication",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.sts.endpoint,"AWS STS endpoint for Glue authentication",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.writer.page-value-count,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.skip-archive,"Skip archiving an old table version when updating a table in the Glue metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.stream-buffer-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-concurrent-file-system-operations,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.max-read-block-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.split-loader-concurrency,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.max-read-block-row-count,"Maximum number of rows read in a batch",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.security,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-refresh-interval,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-partition-drops-per-query,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-split-iterator-threads,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.threads,"Number of threads for parallel operations",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache.cache-missing-stats,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.max-buffer-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.file-status-cache.max-retained-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.s3.storage-class-filter,"Filter based on storage class of S3 object",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.writer-identification,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.compression-codec,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.disable-location-checks,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.writer.block-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.hudi-catalog-name,"Catalog to redirect to when a Hudi table is referenced",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.connect-timeout,"Socket connect timeout for metastore client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-partitions-for-eager-load,"Maximum allowed partitions for a single table scan to be loaded eagerly on coordinator. Certain optimizations are not possible without eager loading.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.read-legacy-short-zone-id,"Allow reads on ORC files with short zone ID in the stripe footer",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.http.client.additional-headers,"Comma separated key:value pairs to be send to metastore as additional headers",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.use-spark-table-statistics-fallback,"Enable usage of table statistics generated by Apache Spark when hive table statistics are not available",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-initial-splits,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.skip-archive,"Skip archiving an old table version when updating a table in the Glue metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.version-compatibility,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.max-initial-split-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.per-transaction-file-status-cache.max-retained-size,"Maximum retained size of file statuses cached by transactional file status cache",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.max-read-block-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore-stats-cache-ttl,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.max-buffer-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.idle-writer-min-file-size,"Minimum data written by a single partition writer before it can be consider as 'idle' and could be closed by the engine",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.experimental.vectorized-decoding.enabled,"Enable using Java Vector API for faster decoding of parquet files",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.proxy-api-id,"ID of Glue Proxy API",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.http.client.bearer-token,"Bearer token to authenticate with a HTTP transport based metastore service",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,parquet.use-bloom-filter,"Use Parquet Bloom filters",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.write-statistics-threads,"Number of threads for parallel statistics writes",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.metastore.http.client.authentication.type,"Authentication mode for thrift http based metastore client",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
465,trino-server-465/plugin/delta-lake/io.trino_trino-hive-465.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.aws.region,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.host,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.aws.access-key,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.port,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.security,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.enabled,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.auth.user,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.auth.password,"",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
465,trino-server-465/plugin/elasticsearch/io.trino_trino-elasticsearch-465.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
465,trino-server-465/plugin/example-http/io.trino_trino-example-http-465.jar,example-http,metadata-uri,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.path-style-access,"Use path-style access for all request to S3",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.source-max-files-per-reader,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key for FTE",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.storage-class,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.region,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.azure.connection-string,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.azure.endpoint,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.sse.type,"Type of S3 server-side encryption for FTE",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
465,trino-server-465/plugin/exchange-filesystem/io.trino_trino-exchange-filesystem-465.jar,exchange-filesystem,exchange.s3.endpoint,"",false
465,trino-server-465/plugin/exchange-hdfs/io.trino_trino-exchange-hdfs-465.jar,exchange-hdfs,hdfs.config.resources,"",false
465,trino-server-465/plugin/exchange-hdfs/io.trino_trino-exchange-hdfs-465.jar,exchange-hdfs,exchange.hdfs.block-size,"Block size for HDFS storage",false
465,trino-server-465/plugin/faker/io.trino_trino-faker-465.jar,faker,faker.locale,"Default locale for generating character based data, specified as a IETF BCP 47 language tag string",false
465,trino-server-465/plugin/faker/io.trino_trino-faker-465.jar,faker,faker.default-limit,"Default number of rows for each table, when the LIMIT clause is not specified in the query",false
465,trino-server-465/plugin/faker/io.trino_trino-faker-465.jar,faker,faker.null-probability,"Default null probability for any column in any table that allows them",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.credentials-path,"Credential file path to google service account",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.data-cache-ttl,"Sheets data expire after write duration",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.read-timeout,"Timeout when reading from Google Sheets API",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.connection-timeout,"Timeout when connection to Google Sheets API",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.credentials-key,"The base64 encoded credentials key",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.write-timeout,"Timeout when writing to Google Sheets API",false
465,trino-server-465/plugin/google-sheets/io.trino_trino-google-sheets-465.jar,google-sheets,gsheets.max-data-cache-size,"Sheet data max cache size",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
465,trino-server-465/plugin/http-event-listener/io.trino_trino-http-event-listener-465.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
465,trino-server-465/plugin/http-server-event-listener/io.trino_trino-http-server-event-listener-465.jar,http-server-event-listener,http-server-event-listener.event-buffer-size,"Event buffer size",false
465,trino-server-465/plugin/http-server-event-listener/io.trino_trino-http-server-event-listener-465.jar,http-server-event-listener,http-server-event-listener.event-ttl,"Event TTL",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.split-loader-parallelism,"Number of threads to run background split loader. A single background split loader is needed per query.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.parquet.use-column-names,"Access Parquet columns using names from the file. If disabled, then columns are accessed using index.Only applicable to Parquet file format.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.query-partition-filter-required,"Require a filter on at least one partition column",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.standard-split-weight-size,"The split size corresponding to the standard weight (1.0) when size based split weights are enabled.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.split-generator-parallelism,"Number of threads to generate splits from partitions.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.max-outstanding-splits,"Maximum outstanding splits in a batch enqueued for processing.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.size-based-split-weights-enabled,"Unlike uniform splitting, size-based splitting ensures that each batch of splits has enough data to process. By default, it is enabled to improve performance.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.per-transaction-metastore-cache-maximum-size,"",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.max-splits-per-second,"Rate at which splits are enqueued for processing. The queue will throttle if this rate limit is breached.",false
465,trino-server-465/plugin/hudi/io.trino_trino-hudi-465.jar,hudi,hudi.columns-to-hide,"List of column names that will be hidden from the query output. It can be used to hide Hudi meta fields. By default, no fields are hidden.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.extended-statistics.collect-on-write,"Collect extended statistics during writes",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.connection-password,"Password for JDBC client",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.read-timeout,"The read timeout for the client.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.snowflake-catalog.password,"Password for Snowflake",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.authentication.token,"The token to use with BEARER authentication",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.compression-codec,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.query-partition-filter-required,"Require a filter on at least one partition column",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.sorted-writing-enabled,"Enable sorted writing to tables with a specified sort order",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.session,"Type of REST catalog sessionType to use when communicating with REST catalog Server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.split-manager-threads,"Number of threads to use for generating splits",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.driver-class,"JDBC driver class name",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.oauth2.server-uri,"The endpoint to retrieve access token from OAuth2 Server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.remove-orphan-files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.oauth2.credential,"The credential to exchange for a token in the OAuth2 client credentials flow with the server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.snowflake-catalog.account-uri,"Snowflake JDBC URI",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.oauth2.token,"The Bearer token which will be used for interactions with the server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.nested-namespace-enabled,"Support querying objects under nested namespace",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.retryable-status-codes,"On connection error to JDBC metastore, retry if it is one of these JDBC status codes",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.vended-credentials-enabled,"Use credentials provided by the REST backend for file system access",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.security,"Authorization protocol to use when communicating with the REST catalog server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.metadata-cache.enabled,"Enables in-memory caching of metadata files on coordinator if fs.cache.enabled is not set to true",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.materialized-views.hide-storage-table,"Hide materialized view storage tables in metastore",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.case-insensitive-name-matching,"Match object names case-insensitively",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.file-format,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.authentication.type,"The authentication type to use",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.schema-version,"JDBC catalog schema version",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.extended-statistics.enabled,"Enable collection (ANALYZE) and use of extended statistics.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.connection-url,"The URI to connect to the JDBC server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.add-files-procedure.enabled,"Allow users to call the add_files procedure",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.glue.cache-table-metadata,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.expire-snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.idle-writer-min-file-size,"Minimum data written by a single partition writer before it can be consider as 'idle' and could be closed by the engine",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.allowed-extra-properties,"List of extra properties that are allowed to be set on Iceberg tables",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.snowflake-catalog.user,"Username for Snowflake",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.catalog-name,"Iceberg JDBC metastore catalog name",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.incremental-refresh-enabled,"Enable Incremental refresh for MVs backed by Iceberg tables, when possible",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.default-warehouse-dir,"The default warehouse to use for Nessie",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.warehouse,"The warehouse location/identifier to use with the REST catalog server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.security,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.snowflake-catalog.role,"Name of Snowflake role to use",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.register-table-procedure.enabled,"Allow users to call the register_table procedure",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a row type",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.enable-compression,"Configure whether compression should be enabled or not.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.client-api-version,"Client API version to use",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.default-warehouse-dir,"The default warehouse directory to use for JDBC",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.ref,"The default Nessie reference to work on",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.uri,"The URI to the REST server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.oauth2.scope,"The scope which will be used for interactions with the server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.case-insensitive-name-matching.cache-ttl,"Duration to keep case insensitive object mapping prior to eviction",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.snowflake-catalog.database,"Snowflake database",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.connection-timeout,"The connection timeout for the client.",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.nessie-catalog.uri,"The URI to connect to the Nessie server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.jdbc-catalog.connection-user,"User name for JDBC client",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.prefix,"The prefix for the resource path to use with the REST catalog server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.catalog.type,"",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.rest-catalog.parent-namespace,"The parent namespace to use with the REST catalog server",false
465,trino-server-465/plugin/iceberg/io.trino_trino-iceberg-465.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
465,trino-server-465/plugin/jmx/io.trino_trino-jmx-465.jar,jmx,jmx.dump-tables,"",false
465,trino-server-465/plugin/jmx/io.trino_trino-jmx-465.jar,jmx,jmx.dump-period,"",false
465,trino-server-465/plugin/jmx/io.trino_trino-jmx-465.jar,jmx,jmx.max-entries,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.config.resources,"Optional config files",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.internal-column-prefix,"Prefix for internal columns",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.truststore.password,"The password for the trust store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.keystore.type,"The file format of the key store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a marker field named '$empty_field_marker' or fail the query",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.buffer-size,"Kafka message consumer buffer size",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.truststore.type,"The file format of the trust store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.truststore.location,"The location of the trust store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.protobuf-any-support-enabled,"True to enable supporting encoding google.protobuf.Any types as JSON",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.key.password,"The password of the private key in the key store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.ssl.keystore.password,"The store password for the key store file",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.default-schema,"Schema name to use in the connector",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.table-names,"Set of tables known to this connector",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.security-protocol,"Kafka communication security protocol",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-465.jar,kafka-event-listener,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.broker-endpoints,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.completed-event.topic,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.publish-created-event,"Whether to publish io.trino.spi.eventlistener.QueryCreatedEvent",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.client-config-overrides,"Comma-separated list of key-value pairs to specify kafka client config overrides. E.g.: 'buffer.memory=67108864,compression.type=zstd'",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.split-completed-event.topic,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.terminate-on-initialization-failure,"Kafka publisher initialization might fail due to network issues reaching the Kafka brokers. This flag controls whether to throw an exception in such cases.",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.created-event.topic,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.env-var-prefix,"When set, Kafka events will be sent with additional metadata populated from environment variables. E.g. if env-var-prefix is set to 'TRINO_INSIGHTS_' and there is an env var TRINO_INSIGHTS_CLUSTER_ID=foo, then Kafka payload metadata will contain CLUSTER_ID=foo.",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.request-timeout,"Timeout value to complete a kafka request.",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.client-id,"",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.publish-completed-event,"Whether to publish io.trino.spi.eventlistener.QueryCompletedEvent",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.publish-split-completed-event,"Whether to publish io.trino.spi.eventlistener.SplitCompletedEvent",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.excluded-fields,"Comma-separated list of field names to be excluded from the Kafka event (their value will be replaced with null). E.g.: 'payload,user'",false
465,trino-server-465/plugin/kafka-event-listener/io.trino_trino-kafka-event-listener-465.jar,kafka-event-listener,kafka-event-listener.anonymization.enabled,"",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
465,trino-server-465/plugin/kinesis/io.trino_trino-kinesis-465.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.client.default-operation-timeout,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.allow-local-scheduling,"Assign Kudu splits to replica host if worker and kudu share the same cluster",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.client.disable-statistics,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.schema-emulation.enabled,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.client.master-addresses,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.schema-emulation.prefix,"",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
465,trino-server-465/plugin/kudu/io.trino_trino-kudu-465.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
465,trino-server-465/plugin/memory/io.trino_trino-memory-465.jar,memory,memory.splits-per-node,"",false
465,trino-server-465/plugin/memory/io.trino_trino-memory-465.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
465,trino-server-465/plugin/memory/io.trino_trino-memory-465.jar,memory,memory.max-data-per-node,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.projection-pushdown-enabled,"Read only required fields from a row type",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.connections-per-host,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.read-preference,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.write-concern,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.max-connection-idle-time,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.cursor-batch-size,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.min-connections-per-host,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.tls.keystore-password,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.required-replica-set,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.allow-local-scheduling,"Assign MongoDB splits to a specific host if worker and MongoDB share the same cluster",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.tls.truststore-path,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.schema-collection,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.socket-timeout,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.tls.truststore-password,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.connection-timeout,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.max-wait-time,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.tls.keystore-path,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.connection-url,"",false
465,trino-server-465/plugin/mongodb/io.trino_trino-mongodb-465.jar,mongodb,mongodb.tls.enabled,"",false
465,trino-server-465/plugin/mysql-event-listener/io.trino_trino-mysql-event-listener-465.jar,mysql-event-listener,mysql-event-listener.db.url,"",false
465,trino-server-465/plugin/mysql/io.trino_trino-mysql-465.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
465,trino-server-465/plugin/mysql/io.trino_trino-mysql-465.jar,mysql,mysql.max-reconnects,"",false
465,trino-server-465/plugin/mysql/io.trino_trino-mysql-465.jar,mysql,mysql.auto-reconnect,"",false
465,trino-server-465/plugin/mysql/io.trino_trino-mysql-465.jar,mysql,mysql.connection-timeout,"",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.policy.row-filters-uri,"URI for fetching row filters - if not set no row filtering will be applied",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.policy.column-masking-uri,"URI for fetching column masks - if not set no masking will be applied",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.allow-permission-management-operations,"Whether to allow permission management (GRANT, DENY, ...) and role management operations - OPA will not be queried for any such operations, they will be bulk allowed or denied depending on this setting",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.log-responses,"Whether to log responses (URI, entire body, status code and headers) received from OPA",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.policy.uri,"URI for OPA policies",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.policy.batch-column-masking-uri,"URI for fetching batch column masks - if not set column-masking-uri will be used",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.policy.batched-uri,"URI for Batch OPA policies - if not set, a single request will be sent for each entry on filtering methods",false
465,trino-server-465/plugin/opa/io.trino_trino-opa-465.jar,opa,opa.log-requests,"Whether to log requests (URI, entire body and headers) prior to sending them to OPA",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.trino.include-query-types,"Which query types emitted by Trino should generate OpenLineage events. Other query types will be filtered out.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.disabled-facets,"Which facets should be removed from OpenLineage events.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.url-params,"List of custom custom url params provided as: ""url-param-1: url param value 1, ..."" ",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.trino.uri,"URI of trino server. Used for namespace rendering.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.namespace,"Override default namespace for job facet.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.api-key,"API Key to use when authenticating against OpenLineage API",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.timeout,"Timeout when making HTTP Requests.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.url,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.endpoint,"Custom path for API receiving the events.",false
465,trino-server-465/plugin/openlineage/io.trino_trino-openlineage-465.jar,openlineage,openlineage-event-listener.transport.type,"Type of transport used to emit lineage information.",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.host,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.access-key,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.keystore-password,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.max-retry-time,"Maximum timeout in case of multiple retries",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.keystore-path,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.security,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.scroll-timeout,"Scroll timeout",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.default-schema-name,"Default schema name to use",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.region,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.port,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.ignore-publish-address,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.verify-hostnames,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.max-http-connections,"Maximum number of persistent HTTP connections to OpenSearch cluster",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.node-refresh-interval,"How often to refresh the list of available nodes in the OpenSearch cluster",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.truststore-password,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.projection-pushdown-enabled,"Read only required fields from a row type",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.scroll-size,"Scroll batch size",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.auth.user,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.request-timeout,"OpenSearch request timeout",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.deployment-type,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.auth.password,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.connect-timeout,"OpenSearch connect timeout",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.http-thread-count,"Number of threads handling HTTP connections to OpenSearch cluster",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.enabled,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.tls.truststore-path,"",false
465,trino-server-465/plugin/opensearch/io.trino_trino-opensearch-465.jar,opensearch,opensearch.aws.secret-key,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.connection-pool.enabled,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.synonyms.enabled,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.number.rounding-mode,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.connection-pool.min-size,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.remarks-reporting.enabled,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.connection-pool.max-size,"",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
465,trino-server-465/plugin/oracle/io.trino_trino-oracle-465.jar,oracle,oracle.fetch-size,"Oracle fetch size, trino specific heuristic is applied if empty",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,ldap.cache-ttl,"",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
465,trino-server-465/plugin/password-authenticators/io.trino_trino-password-authenticators-465.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
465,trino-server-465/plugin/phoenix5/io.trino_trino-phoenix5-465.jar,phoenix5,phoenix.config.resources,"",false
465,trino-server-465/plugin/phoenix5/io.trino_trino-phoenix5-465.jar,phoenix5,query.reuse-connection,"Enables reusing JDBC connection within single Trino query to run metadata queries from Coordinator to remote service",false
465,trino-server-465/plugin/phoenix5/io.trino_trino-phoenix5-465.jar,phoenix5,phoenix.connection-url,"",false
465,trino-server-465/plugin/phoenix5/io.trino_trino-phoenix5-465.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.forbid-segment-queries,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.keystore-password,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.proxy.enabled,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.controller.authentication.user,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.broker.authentication.user,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.proxy-uri,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.segments-per-split,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.truststore-path,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.max-rows-for-broker-queries,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.truststore-password,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.truststore-type,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.connection-timeout,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.controller.authentication.type,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.broker-url,"Provide global broker host and port. Setting this property will disable broker discovery mechanism.",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.fetch-retry-count,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.broker.authentication.type,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.controller-urls,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.port,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.keystore-type,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.metadata-expiry,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.keystore-path,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.controller.authentication.password,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.broker.authentication.password,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.target-segment-page-size,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.grpc.use-plain-text,"",false
465,trino-server-465/plugin/pinot/io.trino_trino-pinot-465.jar,pinot,pinot.prefer-broker-queries,"",false
465,trino-server-465/plugin/postgresql/io.trino_trino-postgresql-465.jar,postgresql,postgresql.include-system-tables,"",false
465,trino-server-465/plugin/postgresql/io.trino_trino-postgresql-465.jar,postgresql,postgresql.array-mapping,"",false
465,trino-server-465/plugin/postgresql/io.trino_trino-postgresql-465.jar,postgresql,postgresql.fetch-size,"Postgresql fetch size, trino specific heuristic is applied if empty",false
465,trino-server-465/plugin/postgresql/io.trino_trino-postgresql-465.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.http.additional-headers,"Comma separated key:value pairs to be sent with the HTTP request to Prometheus as additional headers",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.auth.user,"",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.auth.password,"",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.auth.http.header.name,"Name of the HTTP header to use for authorization",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
465,trino-server-465/plugin/prometheus/io.trino_trino-prometheus-465.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.default-schema,"The schema name to use in the connector",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.password,"Password for a password-protected Redis server",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.user,"Username for a Redis server",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
465,trino-server-465/plugin/redis/io.trino_trino-redis-465.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
465,trino-server-465/plugin/redshift/io.trino_trino-redshift-465.jar,redshift,redshift.fetch-size,"Redshift fetch size, trino specific heuristic is applied if empty",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.refresh-interval,"How often the cluster reloads from the database",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.config-file,"",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,jmx.base-name,"",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.config-db-url,"",false
465,trino-server-465/plugin/resource-group-managers/io.trino_trino-resource-group-managers-465.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
465,trino-server-465/plugin/session-property-managers/io.trino_trino-session-property-managers-465.jar,session-property-managers,session-property-manager.db.url,"",false
465,trino-server-465/plugin/session-property-managers/io.trino_trino-session-property-managers-465.jar,session-property-managers,session-property-manager.db.username,"",false
465,trino-server-465/plugin/session-property-managers/io.trino_trino-session-property-managers-465.jar,session-property-managers,session-property-manager.db.password,"",false
465,trino-server-465/plugin/session-property-managers/io.trino_trino-session-property-managers-465.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
465,trino-server-465/plugin/session-property-managers/io.trino_trino-session-property-managers-465.jar,session-property-managers,session-property-manager.config-file,"",false
465,trino-server-465/plugin/singlestore/io.trino_trino-singlestore-465.jar,singlestore,singlestore.connection-timeout,"",false
465,trino-server-465/plugin/singlestore/io.trino_trino-singlestore-465.jar,singlestore,singlestore.auto-reconnect,"",false
465,trino-server-465/plugin/snowflake/io.trino_trino-snowflake-465.jar,snowflake,snowflake.warehouse,"",false
465,trino-server-465/plugin/snowflake/io.trino_trino-snowflake-465.jar,snowflake,snowflake.database,"",false
465,trino-server-465/plugin/snowflake/io.trino_trino-snowflake-465.jar,snowflake,snowflake.account,"",false
465,trino-server-465/plugin/snowflake/io.trino_trino-snowflake-465.jar,snowflake,snowflake.role,"",false
465,trino-server-465/plugin/snowflake/io.trino_trino-snowflake-465.jar,snowflake,snowflake.http-proxy,"",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.encryption,"Encrypt segments with ephemeral keys",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.ttl,"Maximum duration for the client to retrieve spooled segment before it expires",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.layout.partitions,"Number of file system partitions to use",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.explicit-ack,"Enables deletion of segments on client acknowledgment",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.pruning.interval,"Interval to prune expired segments",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.s3.enabled,"",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.layout,"Spooled segments filesystem layout",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.location,"",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.pruning.batch-size,"Prune expired segments in batches of provided size",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.azure.enabled,"",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.gcs.enabled,"",false
465,trino-server-465/plugin/spooling-filesystem/io.trino_trino-spooling-filesystem-465.jar,spooling-filesystem,fs.segment.pruning.enabled,"Prune expired segments periodically",false
465,trino-server-465/plugin/sqlserver/io.trino_trino-sqlserver-465.jar,sqlserver,sqlserver.experimental.stored-procedure-table-function-enabled,"Allows accessing Stored procedure as a table function",false
465,trino-server-465/plugin/sqlserver/io.trino_trino-sqlserver-465.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
465,trino-server-465/plugin/sqlserver/io.trino_trino-sqlserver-465.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
465,trino-server-465/plugin/sqlserver/io.trino_trino-sqlserver-465.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
465,trino-server-465/plugin/thrift/io.trino_trino-thrift-465.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
465,trino-server-465/plugin/thrift/io.trino_trino-thrift-465.jar,thrift,trino-thrift.max-response-size,"",false
465,trino-server-465/plugin/thrift/io.trino_trino-thrift-465.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
465,trino-server-465/plugin/tpcds/io.trino_trino-tpcds-465.jar,tpcds,tpcds.with-no-sexism,"",false
465,trino-server-465/plugin/tpcds/io.trino_trino-tpcds-465.jar,tpcds,tpcds.splits-per-node,"",false
465,trino-server-465/plugin/tpcds/io.trino_trino-tpcds-465.jar,tpcds,tpcds.split-count,"Number of split to be created. If not specified the number of splits is computed as 'tpcds.splits-per-node * <number of active nodes>'",false
